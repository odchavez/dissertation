\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{fruhwirth2006finite}
\citation{handbookmixtures2019}
\citation{xu2016bayesian}
\citation{rousseau2011asymptotic}
\@writefile{toc}{\contentsline {chapter}{Chapter 3.\hspace  *{1em}Dependent Mixtures: Modelling Cell Lineages}{49}{chapter.3}}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{ch:cell_lineage}{{3}{49}{Dependent Mixtures: Modelling Cell Lineages}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Introduction}{49}{section.3.1}}
\citation{stubbington2017single,miragaia2017single}
\citation{cristinelli2018use}
\citation{wilson2018single,dharampuriya2017tracking}
\citation{stubbington2017single}
\citation{korthauer2016statistical}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Modeling cell lineage data}{50}{subsection.3.1.1}}
\newlabel{sec:intro_cell_lineage}{{3.1.1}{50}{Modeling cell lineage data}{subsection.3.1.1}{}}
\citation{fletcher2017deconstructing}
\citation{street2018}
\citation{fletcher2017deconstructing}
\citation{street2018}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Left panel: Three-dimensional representation of single-cell gene expression profiles based on principal component analysis (data of \cite  {fletcher2017deconstructing}); cells are colored by cluster. Right panel: results using the ``Slingshot'' method of \cite  {street2018}.\relax }}{51}{figure.caption.16}}
\newlabel{fig:ex_data}{{3.1}{51}{Left panel: Three-dimensional representation of single-cell gene expression profiles based on principal component analysis (data of \cite {fletcher2017deconstructing}); cells are colored by cluster. Right panel: results using the ``Slingshot'' method of \cite {street2018}.\relax }{figure.caption.16}{}}
\citation{Shiffman18}
\citation{neal:03}
\citation{street2018}
\citation{Shiffman18}
\citation{xu2016bayesian}
\citation{dpp_original}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Dependent mixture models}{53}{subsection.3.1.2}}
\citation{lindstrom1990nonlinear,alston2012bayesian,lachos2013bayesian}
\citation{HDP}
\citation{chung2011local}
\citation{street2018}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Dependent Mixture Models for Cell Lineage Data}{55}{section.3.2}}
\newlabel{eq:likelihood}{{3.1}{56}{Dependent Mixture Models for Cell Lineage Data}{equation.3.2.1}{}}
\citation{boruuvka1926contribution}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Soft MST-dependent prior}{57}{subsection.3.2.1}}
\newlabel{sec:soft_mst}{{3.2.1}{57}{Soft MST-dependent prior}{subsection.3.2.1}{}}
\newlabel{eq:prior1}{{3.2}{58}{Soft MST-dependent prior}{equation.3.2.2}{}}
\citation{prim1957shortest}
\newlabel{eq:b_cond}{{3.3}{59}{Soft MST-dependent prior}{equation.3.2.3}{}}
\newlabel{eq:mu_cond}{{3.4}{59}{Soft MST-dependent prior}{equation.3.2.4}{}}
\newlabel{eq:mu_cond_eucl1}{{3.5}{60}{Soft MST-dependent prior}{equation.3.2.5}{}}
\newlabel{eq:mu_cond_eucl2}{{3.6}{60}{Soft MST-dependent prior}{equation.3.2.6}{}}
\newlabel{eq:prior_cov}{{3.7}{61}{Soft MST-dependent prior}{equation.3.2.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Hard MST-dependent mixture model}{61}{subsection.3.2.2}}
\newlabel{sec:model2_mst}{{3.2.2}{61}{Hard MST-dependent mixture model}{subsection.3.2.2}{}}
\newlabel{eq:hMST}{{3.8}{61}{Hard MST-dependent mixture model}{equation.3.2.8}{}}
\citation{street2018}
\citation{street2018}
\citation{green1995}
\citation{xu2016bayesian}
\citation{lee2015bayesian}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Posterior Inference}{63}{section.3.3}}
\newlabel{sec:mst_inference}{{3.3}{63}{Posterior Inference}{section.3.3}{}}
\citation{lee2015bayesian}
\citation{xu2016bayesian}
\citation{o1995fractional}
\newlabel{eq:alpha}{{3.9}{64}{Posterior Inference}{equation.3.3.9}{}}
\citation{dahl2006,lau2007bayesian,wade2018bayesian}
\citation{wade2018bayesian}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Optimal partition}{65}{subsection.3.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Estimation of pseudotimes}{66}{subsection.3.3.2}}
\citation{street2018}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Simulated Datasets}{67}{section.3.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Simulation 1}{67}{subsection.3.4.1}}
\citation{wade2018bayesian}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Fit of the s-MST model. The left panel shows the simulation truth. The right panel shows $M=500$ posterior samples of $\tau _k$.\relax }}{68}{figure.caption.18}}
\newlabel{fig:sim1_tree}{{3.2}{68}{Fit of the s-MST model. The left panel shows the simulation truth. The right panel shows $M=500$ posterior samples of $\tau _k$.\relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Posterior density estimate obtained via the s-MST model. The observations are colored according to the optimal cluster labeling.\relax }}{68}{figure.caption.19}}
\newlabel{fig:sim1_dens}{{3.3}{68}{Posterior density estimate obtained via the s-MST model. The observations are colored according to the optimal cluster labeling.\relax }{figure.caption.19}{}}
\citation{wade2018bayesian}
\citation{wade2018bayesian}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Estimated number of clusters $k$ under the hMST model. The methodology of \cite  {wade2018bayesian} was applied to the first 10000 iterations of the transdimensional MCMC under different choices of $\epsilon $ (fraction of data reserved as training) and $k_0$ (value of $k$ used in the initialization of the MCMC algorithm).\relax }}{70}{table.caption.21}}
\newlabel{tab:k_hmst_sim1}{{3.1}{70}{Estimated number of clusters $k$ under the hMST model. The methodology of \cite {wade2018bayesian} was applied to the first 10000 iterations of the transdimensional MCMC under different choices of $\epsilon $ (fraction of data reserved as training) and $k_0$ (value of $k$ used in the initialization of the MCMC algorithm).\relax }{table.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Estimated branching structure of the hMST model with $k_0=8$ and $\epsilon =0.5$ based on the last 5000 MCMC iterations. When the cluster membership indicators are fixed at the point estimate a posteriori, clusters 7 and 8 are empty.\relax }}{70}{figure.caption.22}}
\newlabel{fig:sim1_multiple_trees_hmst}{{3.4}{70}{Estimated branching structure of the hMST model with $k_0=8$ and $\epsilon =0.5$ based on the last 5000 MCMC iterations. When the cluster membership indicators are fixed at the point estimate a posteriori, clusters 7 and 8 are empty.\relax }{figure.caption.22}{}}
\citation{street2018}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Parallel runs of slingshot applied to the simulated data for $k$ ranging from 4 to 11. Clusters are estimated by the best result among 10 random initializations of the k-means algorithm.\relax }}{71}{figure.caption.24}}
\newlabel{fig:sim1_slingshot_multipleK}{{3.5}{71}{Parallel runs of slingshot applied to the simulated data for $k$ ranging from 4 to 11. Clusters are estimated by the best result among 10 random initializations of the k-means algorithm.\relax }{figure.caption.24}{}}
\citation{street2018}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Simulation 2}{72}{subsection.3.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Left panel: Plot of the posterior sampled trees. Right panel: posterior density estimate obtained via the s-MST model. The observations are colored according to the optimal cluster labeling.\relax }}{72}{figure.caption.25}}
\newlabel{fig:sim2_groups}{{3.6}{72}{Left panel: Plot of the posterior sampled trees. Right panel: posterior density estimate obtained via the s-MST model. The observations are colored according to the optimal cluster labeling.\relax }{figure.caption.25}{}}
\citation{korthauer2016statistical}
\citation{perraudeau2017}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Results of posterior estimation of MST. Curves in gray are the posterior sampled MST and the black tree in the point estimate a posteriori. $\alpha $ represents the strength of regularization towards simple MST structures that is implied by the hMST prior on $\unhbox \voidb@x \hbox {\relax \mathversion  {bold}$\mu $}$. $\epsilon $ is the fraction of the data reserved as training for the purpose of building the transdimensional proposals.\relax }}{73}{figure.caption.27}}
\newlabel{fig:sim2_hmst}{{3.7}{73}{Results of posterior estimation of MST. Curves in gray are the posterior sampled MST and the black tree in the point estimate a posteriori. $\alpha $ represents the strength of regularization towards simple MST structures that is implied by the hMST prior on $\bfmu $. $\epsilon $ is the fraction of the data reserved as training for the purpose of building the transdimensional proposals.\relax }{figure.caption.27}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Mouse Data}{73}{section.3.5}}
\citation{zinbwave}
\citation{mardia1979}
\citation{perraudeau2017}
\citation{dahl2006}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Posterior estimates of the latent MST and clustering membership structure based on the last 5000 MCMC iterations. Left panel: independent mixture ($\alpha = 0$). Right panel: MST dependent mixture ($\alpha =2.5$).\relax }}{75}{figure.caption.29}}
\newlabel{fig:fletcher_est_tree}{{3.8}{75}{Posterior estimates of the latent MST and clustering membership structure based on the last 5000 MCMC iterations. Left panel: independent mixture ($\alpha = 0$). Right panel: MST dependent mixture ($\alpha =2.5$).\relax }{figure.caption.29}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces Left panel: Estimated pseudotimes for each cell. The extremes 0 and 1 were chosen arbitrarily. Right panel: posterior standard deviation of pseudotimes for each cell. Axis represent the two components of the MDS transformation.\relax }}{76}{figure.caption.30}}
\newlabel{fig:fletcher_est_pseudo}{{3.9}{76}{Left panel: Estimated pseudotimes for each cell. The extremes 0 and 1 were chosen arbitrarily. Right panel: posterior standard deviation of pseudotimes for each cell. Axis represent the two components of the MDS transformation.\relax }{figure.caption.30}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces Cluster specific boxplots of median posterior pseudotimes obtained for each cell.\relax }}{76}{figure.caption.31}}
\newlabel{fig:fletcher_boxplot}{{3.10}{76}{Cluster specific boxplots of median posterior pseudotimes obtained for each cell.\relax }{figure.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces Multiple runs of slingshot applied to the mouse data. Each plot corresponds to a distinct random initialization of k-means algorithm (k=8). Axis represent the 2 MDS components for dimension reduction.\relax }}{78}{figure.caption.33}}
\newlabel{fig:fletcher_slingshot_kmeans}{{3.11}{78}{Multiple runs of slingshot applied to the mouse data. Each plot corresponds to a distinct random initialization of k-means algorithm (k=8). Axis represent the 2 MDS components for dimension reduction.\relax }{figure.caption.33}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces Multiple runs of slingshot applied to the mouse data. Each plot corresponds to the best result among 10 distinct random initializations of k-means algorithm (k=8). Axis represent the 2 MDS components for dimension reduction.\relax }}{78}{figure.caption.34}}
\newlabel{fig:fletcher_slingshot_kmeans2}{{3.12}{78}{Multiple runs of slingshot applied to the mouse data. Each plot corresponds to the best result among 10 distinct random initializations of k-means algorithm (k=8). Axis represent the 2 MDS components for dimension reduction.\relax }{figure.caption.34}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Discussion}{79}{section.3.6}}
\@setckpt{chapter3}{
\setcounter{page}{80}
\setcounter{equation}{9}
\setcounter{enumi}{2}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{3}
\setcounter{section}{6}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{12}
\setcounter{table}{1}
\setcounter{regular@short}{0}
\setcounter{no@chapters}{0}
\setcounter{regular@short@col}{0}
\setcounter{parentequation}{0}
\setcounter{ContinuedFloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{NAT@ctr}{0}
\setcounter{float@type}{4}
\setcounter{AlgoLine}{7}
\setcounter{algocfline}{2}
\setcounter{algocfproc}{2}
\setcounter{algocf}{2}
\setcounter{Item}{5}
\setcounter{Hfootnote}{1}
\setcounter{bookmark@seq@number}{38}
\setcounter{myth}{0}
\setcounter{mylem}{0}
\setcounter{mypro}{0}
\setcounter{mydef}{0}
\setcounter{myrem}{0}
\setcounter{exem}{0}
\setcounter{thm}{0}
\setcounter{ax}{0}
\setcounter{defn}{0}
\setcounter{rem}{0}
\setcounter{section@level}{1}
}
